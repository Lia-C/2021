## Introduction

Machine co-creativity continues to grow and attract a wider audience to machine learning. Generative models, for example, have enabled new types of media creation across language, images, and music--including recent advances such as CLIP, VQGAN, and DALL·E. This one-day workshop will broadly explore topics in the applications of machine learning to creativity and design, which includes:

**State-of-the-art algorithms for the creation of new media**. Machine learning models achieving state-of-the-art in traditional media creation tasks (e.g., image, audio, or video synthesis) that are also being used by the artist community will be showcased.

**Artist accessibility of machine learning models**. Researchers building the next generation of machine learning models for media creation will be challenged in understanding the accessibility needs of artists. Artists and Human Computer interaction / User Experience community members will be encouraged to engage in the conversation.

**The sociocultural and political impact of these new models**. With the increased popularity of generative machine learning models, we are witnessing these models start to impact our everyday surroundings, ranging from racial and gender bias in algorithms and datasets used for media creation to how new media manipulation tools may erode our collective trust in media content.

**Artistic applications**. We will hear directly from some of the artists who are adopting machine learning--including deep learning and reinforcement learning--as part of their own artistic process as well as showcasing their work.  

This workshop will aim to balance addressing the technical issues and challenges of applying the latest machine learning models and techniques to creativity and design with the broader sociocultural and political issues that surround this area of research. The goal of this workshop is to bring together researchers and artists interested in exploring the intersection of human creativity and machine learning and foster collaboration between them, as well as promote the sharing of ideas, perspectives, new research, artwork, and artistic needs.

As in previous years the workshop will include an open call for a display of artworks incorporating machine learning techniques. These works will be collected and presented online, providing a more personal forum for sharing artifacts created with machine learning techniques as well as providing a snapshot of the current creative machine learning landscape to the broader public.

## Invited Speakers

[Devi Parikh](https://twitter.com/deviparikh), Research Scientist at Facebook AI Research (FAIR) and Associate Professor in the School of Interactive Computing at Georgia Tech.

[Hypereikon](https://twitter.com/hypereikon), Art duo specializing in Generative Visual Arts.

[Joel Simon](https://twitter.com/_joelsimon), Multidisciplinary Artist, Toolmaker, and Researcher. Founder and Director of [Morphogen](https://twitter.com/studiomorphogen).

[Kenric Allado-McDowell](https://twitter.com/kalladomcdowell), Writer, Speaker, and Musician. Co-author of the book [Pharmako-AI](https://ignota.org/products/pharmako-ai).

[Mark Riedl](https://twitter.com/mark_riedl), Professor in the Georgia Tech School of Interactive Computing and Associate Director of the Georgia Tech Machine Learning Center.

[Moisés Horta Valenzuela](https://twitter.com/hexorcismos), Sound Artist, Electronic Musician, and Creative Technologist.

## Schedule and format

All times are in EST (UTC -5).

Some of the below sessions will occur on our Discord server and some will occur in our Zoom livestream. You will find links to access all sessions at our [NeurIPS workshop website](https://neurips.cc/virtual/2021/workshop/21876) (registered participants only).

| Time    | Event  |
|---------|--------|
| 11:15 | Welcome and Introduction<br/>*TBA, Zoom* |
| 11:30 | Poster Session 1<br/>*All Posters, Discord* |
| 12:30 | Computers, Creativity, and Lovelace<br/>*Speaker Presentation by Mark Riedl, Zoom* |
| 13:00 | From Technologies to Tools<br/>*Speaker Presentation by Joel Simon, Zoom* |
| 13:30 | Interspecies Intelligence in Pharmako-AI<br/>*Speaker Presentation by Kenric Allado-McDowell, Zoom* |
| 14:00 | Art Show<br/>*Zoom* |
| 14:30 | Q&A Panel Discussion 1<br/>*Mark Riedl, Joel Simon, and Kenric Allado-McDowell, moderated by TBA, Zoom + Rocketchat* |
| 15:00 | Social 1<br/>*Discord* |
| 15:30 | StyleCLIPDraw: Coupling Content and Style in Text-to-Drawing Synthesis<br/>*Paper Oral by Peter Schaldenbrand et al., Zoom* |
| 15:40 | Soundify: Matching Sound Effects to Video<br/>*Paper Oral by David Chuan-En Lin et al., Zoom* |
| 15:50 | Controllable and Interpretable Singing Voice Decomposition via Assem-VC<br/>*Paper Oral by Kang-wook Kim et al., Zoom* |
| 16:00 | Extending the Vocabulary of Fictional Languages using Neural Networks<br/>*Paper Oral by Thomas Zacharias et al., Zoom* |
| 16:10 | Jabberwocky<br/>*Artwork Spotlight by Vadim Epstein, Zoom* |
| 16:15 | Iterative Iterative<br/>*Artwork Spotlight by Erin Smith, Zoom* |
| 16:20 | Artificial Intelligence for High Heel Shoe Design<br/>*Artwork Spotlight by Sophia Neill, Zoom* |
| 16:25 | text2pixelart<br/>*Artwork Spotlight by Alexey Tikhonov, Zoom* |
| 16:30 | Poster Session 2<br/>*All Posters, Discord* |
| 17:30 | AI for Augmenting Human Creativity<br/>*Speaker Presentation by Devi Parikh, Zoom* |
| 18:00 | Okachihuali: Strategies for New Future Building with AI Art<br/>*Speaker Presentation by Moisés Horta Valenzuela, Zoom* |
| 18:30 | Imaginatory Processes with VQGANxCLIP<br/>*Speaker Presentation by Hypereikon, Zoom* |
| 19:00 | Art Show (repeated)<br/>*Zoom* |
| 19:30 | Q&A Panel Discussion 2<br/>*Devi Parikh, Moisés Horta Valenzuela, and Hypereikon, moderated by TBA, Zoom + Rocketchat* |
| 20:00 | Closing<br/>*TBA, Zoom* |
| 20:15 | Social 2<br/>*Discord* |
| 21:00 | End |

## Accepted papers

To be announced.

## Important Dates

~~17 September 2021, 11:59 UTC: Submission due date for papers and art~~<br>
~~24 September 2021, 11:59 UTC: Submission due date for papers and art (Extended)~~<br>
~~25 September 2021, 11:59 UTC: Submission due date for papers and art (Extended+)~~<br>

~~22 October 2021: Acceptance notification for papers and art~~<br>

~~05 November 2021, 01:00 UTC: Camera-ready (or Revisions) due date for papers and art~~<br>
~~11 November 2021, 01:00 UTC: Camera-ready (or Revisions) due date for papers and art (Extended)~~<br>

~~16 November 2021: Final acceptance/rejection notification for revised artwork submissions~~<br>

6–14 December 2021: NeurIPS Conference

13 December 2021: Workshop

## Contact

If you have any questions, please contact us at [neuripscreativityworkshop@googlegroups.com](mailto:neuripscreativityworkshop@googlegroups.com)

Workshop website: [https://neuripscreativityworkshop.github.io/2021](https://neuripscreativityworkshop.github.io/2021)

Previous years:

* [2020 workshop](https://neuripscreativityworkshop.github.io/2020) (Everywhere, Online)
* [2019 workshop](http://neurips2019creativity.github.io/) (Vancouver, Canada)
* [2018 workshop](https://nips2018creativity.github.io/) (Montreal, Canada)
* [2017 workshop](https://nips2017creativity.github.io/) (Long Beach, CA, USA)

The art submissions from previous years can be viewed [here](http://www.aiartonline.com/)

## How to attend

A registration ticket must be purchased on [neurips.cc](https://neurips.cc/). This will allow you to access [our website](https://neurips.cc/virtual/2021/workshop/21876) on NeurIPS with links to the livestream, poster session and socials.

## Organisers

[Tom White](https://twitter.com/dribnet), Victoria University of Wellington

[Mattie Tesfaldet](https://twitter.com/mattierialgirl), McGill University / MILA

[Samaneh Azadi](https://twitter.com/smnh_azadi), Facebook AI Research (FAIR)

[Daphne Ippolito](https://twitter.com/daphneipp), University of Pennsylvania / Google Brain

[Lia Coleman](https://twitter.com/Lialialiacole), Rhode Island School of Design

[David Ha](https://twitter.com/hardmaru), Google Brain
